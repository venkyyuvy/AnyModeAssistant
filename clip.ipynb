{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone - Generate CLIP embeddings from images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda9SetDeviceEi'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "\n",
    "# Load the CLIP model and processor\n",
    "model_name = \"openai/clip-vit-base-patch16\"\n",
    "device = \"cuda\"\n",
    "model = CLIPModel.from_pretrained(model_name).to(device)\n",
    "processor = CLIPProcessor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = transforms.Resize((224, 224))(image)\n",
    "    image = transforms.ToTensor()(image)\n",
    "    return image.unsqueeze(0)\n",
    "\n",
    "# Encode the image\n",
    "def encode_image(image_path):\n",
    "    # image = preprocess_image(image_path)\n",
    "    inputs = processor(text=[\"\"],images=image_path, return_tensors=\"pt\", padding=True)\n",
    "    inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}  # \n",
    "    outputs = model(**inputs)\n",
    "    img_embedding = outputs.image_embeds\n",
    "    return img_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
      "3697it [6:08:59,  5.99s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "class CustomImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = [os.path.join(root_dir, f) for f in os.listdir(root_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, img_path\n",
    "\n",
    "# Define the image transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create an instance of the custom dataset\n",
    "image_folder = \"era/train2017\"\n",
    "emb_path = \"era/img_emb\"\n",
    "custom_dataset = CustomImageDataset(root_dir=image_folder, transform=transform)\n",
    "\n",
    "# Create a data loader with batch size\n",
    "batch_size = 32  # Adjust the batch size based on memory constraints\n",
    "data_loader = DataLoader(custom_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# image_paths = []\n",
    "# Iterate through the data loader to process images in batches\n",
    "for ix, (batch_images, batch_image_paths) in tqdm(enumerate(data_loader)):\n",
    "    # Process the images in the current batch\n",
    "    image_embedding = encode_image(batch_images)\n",
    "    # image_paths.extend(batch_image_paths)\n",
    "    torch.save(image_embedding, os.path.join(emb_path, f'embeddings_batch{ix}.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_list = []\n",
    "for i in range(3697):\n",
    "    file_path = os.path.join(emb_path, f\"embeddings_batch{i}.pth\")\n",
    "    tensor_list.append(torch.load(file_path))\n",
    "embs = torch.concat(tensor_list, axis=0)\n",
    "torch.save(embs,\"img_embeddings.pth\")\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_emb = torch.load(\"img_embeddings.pth\").unsqueeze(1).to(\"cpu\")\n",
    "\n",
    "with open(\"./image_names.json\", 'r') as file:\n",
    "    image_names = json.load(file)\n",
    "imgEmbDict = dict(zip(image_names, img_emb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(imgEmbDict, 'img_embeddings_dict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 857191,
     "sourceId": 1462296,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30627,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
